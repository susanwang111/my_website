---
title: "Project 2 Climate Change"
subtitle: "Climate change and temperature anomalies"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---


```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
```



To study climate change, we can find data on the *Combined Land-Surface Air and Sea-Surface Water Temperature Anomalies* in the Northern Hemisphere at [NASA's Goddard Institute for Space Studies](https://data.giss.nasa.gov/gistemp). The [tabular data of temperature anomalies can be found here](https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt)

To define temperature anomalies:

```{r weather_data, cache=TRUE}

weather <- 
  read_csv("https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv", 
           skip = 1, 
           na = "***")

```

For each month and year, the dataframe shows the deviation of temperature from the normal (expected). 

Select the year and the twelve month variables from the `weather` dataset. Convert the dataframe from wide to 'long' format.Name the new dataframe as `tidyweather`, name the variable containing the name of the month as `month`, and the temperature deviation values as `delta`.

```{r tidyweather}

tidyweather <- weather %>% 
               select(Year,Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec) %>% 
               pivot_longer(c(Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec),
                            names_to = "Month",
                            values_to = "delta")

tidyweather
```

## Plotting Information

Let us plot the data using a time-series scatter plot, and add a trend line. To do that, we first need to create a new variable called `date` in order to ensure that the `delta` values are plot chronologically. 

```{r scatter_plot}

tidyweather<- tidyweather %>%
              mutate(date = ymd(paste(as.character(Year), Month, "1")),
              month = month(date, label=TRUE),
              year = year(date))

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color="red") +
  theme_bw() +
  labs (title = "Weather Anomalies",
        x = "Date",
        y = "Delta") +
  NULL

```


The graph shows clearly that as time has gone on, the number of weather anomalies has gone up drastically. This corroborates the claim that scientists have made on humans bringing about climate change and the effect of increased greenhouse gas emissions on our environment.


Is the effect of increasing temperature more pronounced in some months? Use `facet_wrap()` to produce a separate scatter plot for each month, again with a smoothing line.

```{r facet_wrap, echo=FALSE}

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color="red") +
  theme_bw() +
  labs (title = "Weather Anomalies",
        x = "Date",
        y = "Delta") +
  facet_wrap(~fct_reorder(Month,date)) +
  NULL

```


The graphs show a roughly similar trend in weather anomalies in each individual month. The effects of increasing temperature are slightly more pronounced in November and December. This may be because these months come at the heart of winter and therefore show a bit greater variation and more extreme values in the northern hemisphere.


It is sometimes useful to group data into different time periods to study historical data. For example, we often refer to decades such as 1970s, 1980s, 1990s etc. to refer to a period of time. NASA calculates a temperature anomaly, as difference form the base period of 1951-1980. The code below creates a new data frame called `comparison` that groups data in five time periods: 1881-1920, 1921-1950, 1951-1980, 1981-2010 and 2011-present. 

We remove data before 1800 and before using `filter`. Then, we use the `mutate` function to create a new variable `interval` which contains information on which period each observation belongs to. We can assign the different periods using `case_when()`.


```{r intervals}

comparison <- tidyweather %>% 
              filter(Year>= 1881) %>%     
              mutate(interval = case_when(
                    Year %in% c(1881:1920) ~ "1881-1920",
                    Year %in% c(1921:1950) ~ "1921-1950",
                    Year %in% c(1951:1980) ~ "1951-1980",
                    Year %in% c(1981:2010) ~ "1981-2010",
                    TRUE ~ "2011-present"))

```

Now that we have the `interval` variable, we can create a density plot to study the distribution of monthly deviations (`delta`), grouped by the different time periods we are interested in. Set `fill` to `interval` to group and colour the data by different time periods.

```{r density_plot}

ggplot(comparison, aes(x=delta, fill=interval)) +
  geom_density(alpha=0.2) +   
  theme_bw() +                
  labs (title = "Density Plot for Monthly Temperature Anomalies",
        x = "Delta",
        y = "Density")

```


The density plot shows the trend of how the delta (monthly deviations) has progressively increased as time has gone on. This is what we expect as, in line with modern conceptions of climate change, the number of monthly temperature anomalies has gone up as humankind’s industrial output has increased. Between 1881-1920, we can see a negative delta. This could be explained by the massive volcanic eruption of Krakatoa in 1883 whose ash clouds were so significant that they blocked and reflected more than usual the Sun’s rays, thus reducing global temperatures. 


So far, we have been working with monthly anomalies. However, we might be interested in average annual anomalies. We can do this by using `group_by()` and `summarise()`, followed by a scatter plot to display the result. 

```{r averaging}

average_annual_anomaly <- tidyweather %>% 
  group_by(Year) %>%   #grouping data by Year
  summarise(na.rm=TRUE,annual_average_delta=mean(delta)) 

ggplot(average_annual_anomaly, aes(x=Year, y= annual_average_delta))+
  geom_point()+
  geom_smooth() +
  theme_bw() +
  labs (title = "Average Yearly Anomaly", 
        x = "Year",
        y = "Average Annual Delta")

```


From the last graph, we saw how each period’s delta was either 0 or close to 0, until after the 1950s when human fossil fuel emissions increased. Here, we can observe across the whole period how the number of anomalies has consistently grown, especially since 1960. This is also consistent with our notion of global warming. 

## Confidence Interval for `delta`

[NASA points out on their website](https://earthobservatory.nasa.gov/world-of-change/decadaltemp.php) that 

> A one-degree global change is significant because it takes a vast amount of heat to warm all the oceans, atmosphere, and land by that much. In the past, a one- to two-degree drop was all it took to plunge the Earth into the Little Ice Age.

Then we construct a confidence interval for the average annual delta since 2011, both using a formula and using a bootstrap simulation with the `infer` package. Recall that the dataframe `comparison` has already grouped temperature anomalies according to time intervals; we are only interested in what is happening  between 2011-present.

```{r, calculate_CI_using_formula}

formula_ci <- comparison %>% 
              filter(interval %in% "2011-present") %>% 
              summarise(mean_delta = mean(delta),
              sd_delta = sd(delta),
              count = n(),
              t_critical = qt(0.975,count-1),
              se_delta = sd(delta)/sqrt(count),
              margin_of_error = t_critical * se_delta,
              delta_low = mean_delta - margin_of_error,
              delta_high = mean_delta + margin_of_error)

formula_ci
```


```{r, calculate_CI_using_bootstrap}

library(infer)
set.seed(1234)
boot_delta <- comparison %>%
              filter(interval %in% "2011-present") %>%
              specify(response = delta) %>%
              generate(reps = 1000, type = "bootstrap") %>%
              calculate(stat = "mean")

bootstrapping_CI <- boot_delta %>% 
                    get_confidence_interval(level = 0.95, type = "percentile")

bootstrapping_CI

```

## Implication

By constructing a confidence interval using one sample, the data show us that there is a 95% chance that the true average annual data mean is contained in the confidence interval (CI) between 1.01 and 1.11. The CI previously mentioned was constructed using one sample (the data) for the northern hemisphere, allowing us to infer about temperature anomalies in that zone of the earth, but not for the entire planet. It is not possible to know with certainty where the true parameter of a mean lies with only one sample (in this case, data for the northern hemisphere). To address the sampling variability problem, bootstrapping may be useful. Repeatedly sampling with replacement via Bootstrapping (BTS) creates resamples (in this case 1,000) and finally calculates 1,000 mean statistics to calculate a new confidence interval. Using the BTS method, there is a 95% chance that the true average annual delta mean is between 1.02 and 1.11. An additional benefit of using BTS is that the data distribution will approach a normal one because of the Central Limit Theorem.

